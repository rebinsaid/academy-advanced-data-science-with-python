{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a3bade8-623d-4f91-965a-2a73c1ecf489",
   "metadata": {},
   "source": [
    "# Polynomial Features and Interactions\n",
    "\n",
    "With the existing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f993b4-0195-43ec-9a4d-44b3a88c41c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (OneHotEncoder,\n",
    "                                   PolynomialFeatures, \n",
    "                                   KBinsDiscretizer)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f5b0b-83f4-44c0-94af-1b4a05fa5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke = pd.read_csv('../data/stroke.csv').rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ec9c7-eec4-46f7-8d21-2a0450242d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable definitions\n",
    "categorical_cols = ['work_type', 'smoking_status', 'who', 'gender', 'residence_type']\n",
    "numeric_cols = ['age', 'hypertension', 'heart_disease', 'ever_married', 'avg_glucose_level', 'height', 'weight']\n",
    "missing_cols = ['age','height', 'weight']\n",
    "drop_cols = ['id','address']\n",
    "\n",
    "target = 'stroke'\n",
    "\n",
    "def create_Xy(df, drop_cols, target_col):\n",
    "    df = df.drop(columns=drop_cols)\n",
    "    return (\n",
    "        df.drop(columns=target_col),\n",
    "        df[target_col]\n",
    "    )\n",
    "\n",
    "X, y = stroke.pipe(create_Xy, \n",
    "                   drop_cols=drop_cols, \n",
    "                   target_col=target,\n",
    "                   )\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 123,\n",
    "                                                    stratify = y,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be406c9-3f40-4f3f-a5e4-d630c3970fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = Pipeline(steps = [\n",
    "    ('onehot', OneHotEncoder(drop = \"if_binary\")),\n",
    "])\n",
    "\n",
    "impute = Pipeline(steps = [\n",
    "    ('impute', SimpleImputer(strategy ='mean')),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers = [\n",
    "    ('onehot', onehot, categorical_cols),\n",
    "    ('impute', impute, numeric_cols)\n",
    "], remainder = 'passthrough')\n",
    "\n",
    "base_model = RandomForestClassifier(class_weight='balanced',\n",
    "                                    max_depth=5,\n",
    "                                    random_state=123,\n",
    "                                    )\n",
    "\n",
    "base_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', base_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1835ba2-16bf-4f39-844f-5a64141f3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_baseline_train_probs = base_pipeline.predict_proba(X_train)[:,1]\n",
    "y_baseline_test_probs = base_pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(f'Train AUC: {round(roc_auc_score(y_train, y_baseline_train_probs),4)}',\n",
    "      f'Test AUC: {round(roc_auc_score(y_test, y_baseline_test_probs),4)}',\n",
    "      sep='\\n'\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f5bc37-fe46-4c36-948a-7653ba05a22c",
   "metadata": {},
   "source": [
    "<a id='polynomial'></a>\n",
    "### Polynomial Features and Interactions\n",
    "\n",
    "***Polynomial features*** are created by raising the original features to a power greater than one. For example, a simple linear model could be expressed as $y(x_i) = a*x_i + b$ with $y$ being the prediction, $x_i$ the feature, and $a$ and $b$ the coefficients. We could now simply add a polynomial feature, like so: $y(x_i) = a*x_i + c*x_i^2 + b$. For some models (especially those that are linear in nature), polynomial features can be a useful addition.\n",
    "\n",
    "***Interactions*** are essentially just multiplications of two (or more) features. We could, for example, add an interaction to the previous equation like so: $y(x_i) = a*x_i + c*x_i^2 + d*x_i*x_i^2 + b$. Here, the term $d*x_i*x_i^2$ is the interaction between $x_i$ and $x_i^2$. Interactions can also happen between features like $x_1 * x_2$ with $x_1$ being one feature and $x_2$ another.\n",
    "\n",
    "**Why can they be useful?**\n",
    "\n",
    "Polynomials and interactions can help:\n",
    "\n",
    "1. capture non-linear and complex relationships between the independent variable(s) and the target variable,\n",
    "2. add additional model flexibility by including interactions within and between different degree polynomials,\n",
    "3. and therefore (potentially) better capture the complexity of the underlying data patterns.\n",
    "\n",
    "In `sklearn`, adding polynomial features and interactions is as easy as using the `PolynomialFeatures` class ([click for documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)), and adding it to our existing pipeline.\n",
    "\n",
    "Let's add some 2nd degree polynomials to all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a33119-7f89-4ec0-b0d2-3fe96ff7d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cols = ['age','bmi','avg_glucose_level']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers = [\n",
    "    ('onehot', onehot, categorical_cols),\n",
    "    ('impute', impute, missing_cols),\n",
    "], remainder='passthrough')\n",
    "\n",
    "poly_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    # Since we do it with all features, we could also just add it here\n",
    "    ('polynomial', PolynomialFeatures(degree = 2, interaction_only = False)),\n",
    "    ('model', base_model)\n",
    "])\n",
    "\n",
    "poly_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_poly_train_probs = poly_pipeline.predict_proba(X_train)[:,1]\n",
    "y_poly_test_probs = poly_pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(f'Train AUC: {round(roc_auc_score(y_train, y_poly_train_probs),4)}',\n",
    "      f'Test AUC: {round(roc_auc_score(y_test, y_poly_test_probs),4)}',\n",
    "      sep='\\n'\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
