{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML project\n",
    "\n",
    "### The setup\n",
    "\n",
    "A former colleague of yours was working on a promising data-focused project, but unfortunately he recently got fired (for unknown reasons), so you are taking the project over. **Your goal** will be to kickstart this project, and turn it into a successful data-driven use case rather than an immature experimental notebook that it is right now. You will have to **improve the approach** started by your colleague, **rethink** some of the more immature techniques, **substantially expand and reinforce** the project, as well as verify that it actually brings business value.\n",
    "\n",
    "<img src=\"images/coworker.jpg\" width=400>\n",
    "\n",
    "### Project background\n",
    "\n",
    "You are working for a bike rental company that hopes to optimize its bicycle availability at various rental locations. You have access to their past data that contains the hourly and daily count of bike rentals between years 2011 and 2012 with the corresponding weather and seasonal information. Our target variable is **cnt** - the number of bikes rented out at a particular moment. Below is a description of the remaining variables:\n",
    "\n",
    "- **datetime**: date and time when each log of bike rentals was made\n",
    "- **weathersit**: weather situation at the moment of the log \n",
    "    1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "    2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "    3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "    4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "- **temp**: Normalized temperature in Celsius. The values are derived via (t-tmin)/(tmax-tmin), tmin=-8, t_max=+39 \n",
    "- **atemp**: Normalized feeling temperature in Celsius. The values are derived via (t-tmin)/(tmax-tmin), tmin=-16, t_max=+50\n",
    "- **hum**: Normalized humidity. The values are divided to 100 (max)\n",
    "- **windspeed**: Normalized wind speed. The values are divided to 67 (max)\n",
    "- **registered**: count of registered users among those who rented bikes\n",
    "- **cnt**: count of all rental bikes including both unregistered and registered users\n",
    "\n",
    "**Important assumption**: additional research of the bike rental company showed that each rental location at each moment in time can be considered *independent* of every other bike rental log in the dataset.\n",
    "\n",
    "The dataset can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bikes_df = pd.read_csv('data/bike_rentals.csv')\n",
    "bikes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Old Project\n",
    "\n",
    "Below you can find *untouched* the analysis made by your former colleague. Other stakeholders have communicated to you, that according to that colleague, the below code successfully develops a bike demand forecasting framework. So you would not need to change much, and just need to polish the code. You however have doubts about it and want to first **assess the adequacy of the approach**, **outline potential improvements**, and **redo/add certain steps**. \n",
    "\n",
    "### Assignment 1\n",
    "\n",
    "Go through the code below and try to assess:\n",
    "\n",
    "- what it might be missing\n",
    "- where the approach might be questionable/wrong\n",
    "- any code style / logic issues\n",
    "- whether the built application is usable and addresses the goal\n",
    "\n",
    "Make notes about any of the above, those will be discussed with other training participants.\n",
    "\n",
    "*Note*: your former colleague's code is given as Python comments (# text)\n",
    "\n",
    "*Note 2*: pause after Block #4  (where a test set is separated), the rest will be discussed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---------- Colleague's code begins here ---------- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. I first drop features that would be too hard to use for building a demand forecasting application \n",
    "#+ drop any missing values (there are not many anyways)\n",
    "BikePrepData=bikes_df.drop(['datetime','atemp'],axis=1).dropna()\n",
    "\n",
    "print('data size is ' + str(BikePrepData.shape))\n",
    "BikePrepData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Then I remove outliers (very low or very high values) in the target variable and corresponding other values\n",
    "#I determine outlier based on whether they are much smaller or larger than the mean value of the target\n",
    "\n",
    "print(\"target mean value:\")\n",
    "print(round(bikes_df['cnt'].mean(),2))\n",
    "\n",
    "# therefore anything below 10 would be rather small and anything above 890 would be rather large, so those can be considered outliers\n",
    "\n",
    "BikePrepData=BikePrepData[BikePrepData.cnt>=10]\n",
    "BikePrepData=BikePrepData[BikePrepData.cnt<=890]\n",
    "\n",
    "\n",
    "BikePrepData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(BikePrepData.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 here I add a few aditional features that may be useful for forecasting:\n",
    "# squared temperature and a sum of all present features:\n",
    "\n",
    "BikePrepData['sqTemp'] = BikePrepData.temp * 2\n",
    "BikePrepData['RowSum'] = [sum(BikePrepData.loc[i]) for i in BikePrepData.index]\n",
    "BikePrepData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Finally, I scale all features by subtracting their means and deviding by standard deviations\n",
    "# and separate a random subset of the data for future testing\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#DataScaled = StandardScaler().fit_transform(BikePrepData)\n",
    "\n",
    "DataMeans = BikePrepData.mean()\n",
    "DataStds = BikePrepData.std()\n",
    "\n",
    "DataScaled = ((BikePrepData - DataMeans) / DataStds)\n",
    "\n",
    "# the target variable is also separated from the features below\n",
    "\n",
    "TrainData = DataScaled.sample(frac=0.65)\n",
    "TrainTarget = BikePrepData[BikePrepData.index.isin(TrainData.index)]['cnt'].values #BikePrepData is used here to avoid using scaled 'cnt'\n",
    "TrainData = TrainData.drop(['cnt'],axis=1).values\n",
    "\n",
    "TestData = DataScaled.sample(frac=0.35)\n",
    "TestTarget = BikePrepData[BikePrepData.index.isin(TestData.index)]['cnt'].values\n",
    "TestData = TestData.drop(['cnt'],axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pause here. The rest will be discussed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Below I train, improve and evaluate two ML approaches to forecast bike rental demand\n",
    "#  Model 1 is a decision tree (popular, interpretable and just generally great)\n",
    "#  Model 2 is a Suport Vector Machine, also very popular and often powerful\n",
    "\n",
    "model1 = DecisionTreeRegressor()\n",
    "model1.fit(TrainData, TrainTarget)\n",
    "y_pred1 = model1.predict(TestData)\n",
    "\n",
    "model2 = SVR()\n",
    "model2.fit(TrainData, TrainTarget)\n",
    "y_pred2 = model2.predict(TestData)\n",
    "\n",
    "# Root-Mean-Absolute-Error is used below as our main metric, it could be a good alternative too RMSE\n",
    "\n",
    "print('RMAE with model 1:')\n",
    "print(round(mean_absolute_error(TestTarget, y_pred1)**0.5,2))\n",
    "\n",
    "print('RMAE with model 2:')\n",
    "print(round(mean_absolute_error(y_pred2, TestTarget)**0.5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1 has a higher score and is therefore selected. \n",
    "#It already has a pretty good score (only mistaken by ~14 bikes on average, but we will try to further improve it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 best parameters for model 1 are selected here\n",
    "# based on which parameters result in a higher score on the test set\n",
    "\n",
    "BestParams = []\n",
    "BestScore = 0\n",
    "\n",
    "for Depth in range(1,10, 2):\n",
    "    for criterion in [\"mse\", \"mae\"]:\n",
    "        for state in [1, 100, 999]:\n",
    "            \n",
    "            model = DecisionTreeRegressor(max_depth=Depth, criterion=criterion, random_state=state)\n",
    "            model.fit(TrainData, TrainTarget)\n",
    "            pred = model.predict(TestData)\n",
    "            CurrentScore = round(mean_absolute_error(TestTarget, pred)**0.5,2)\n",
    "            \n",
    "            if CurrentScore > BestScore:\n",
    "                BestParams = [Depth, criterion, state]\n",
    "                BestScore = CurrentScore\n",
    "\n",
    "print(\"the best model has these parameters\" + str(BestParams))\n",
    "print(\"and this score:\" + str(BestScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfortunately the score is still lower than what we had for model 1, so model 1 will be used as the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BikePrepData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Building a user interface (productionizing our solution)\n",
    "\n",
    "# Notice that is a MVP, so only temperature, wind speed and weather situation are accepted as inputs for predictions\n",
    "\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "\n",
    "def GetPred(index=20000, \n",
    "             weathersit=BikePrepData['weathersit'].mean(),\n",
    "             temp=BikePrepData['temp'].mean(),\n",
    "             hum=BikePrepData['hum'].mean(),\n",
    "             windspeed=BikePrepData['windspeed'].mean(),\n",
    "             registered=BikePrepData['registered'].mean(),\n",
    "             RowSum=BikePrepData['RowSum'].mean()):\n",
    "    \n",
    "    sqTemp = temp ** 2\n",
    "\n",
    "    df = pd.DataFrame({'index': {0:index},\n",
    "                       'weathersit': {0:weathersit},\n",
    "                       'temp': {0:temp},\n",
    "                       'hum': {0:hum},\n",
    "                       'windspeed': {0:windspeed},\n",
    "                       'registered': {0:registered},\n",
    "                       'cnt' : {0:10000}, # need it to correctly scale\n",
    "                       'sqTemp': {0:sqTemp},\n",
    "                       'RowSum' : {0:RowSum},\n",
    "                       \n",
    "                       })    \n",
    "    \n",
    "    #scaling inputs\n",
    "    df = ((df - DataMeans) / DataStds).drop(['cnt'],axis=1)\n",
    "\n",
    "    display(df)\n",
    "    prediction = round(model1.predict(df)[0],0)\n",
    "    print(\"Predicted Bike Demand is: \" + str(prediction))\n",
    "        \n",
    "style = {'description_width': 'initial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipywidgets.interact(GetPred,\n",
    "                    temp=ipywidgets.widgets.BoundedFloatText(\n",
    "                        min=5, \n",
    "                        max=20, \n",
    "                        step=1, \n",
    "                        value=15,\n",
    "                        description=\"How warm is it out there?\",\n",
    "                        style=style),\n",
    "                    windspeed=ipywidgets.widgets.BoundedFloatText(\n",
    "                        min=0, \n",
    "                        max=1, \n",
    "                        step=0.05, \n",
    "                        value=0.5,\n",
    "                        description=\"What is the weather speed?\",\n",
    "                        style=style),\n",
    "                    weathersit=ipywidgets.widgets.BoundedFloatText(\n",
    "                        min=1, \n",
    "                        max=4,\n",
    "                        step=1, \n",
    "                        value=1,\n",
    "                        description=\"What is the weather situation out there?\",\n",
    "                        style=style)\n",
    "                   );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it works!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
