{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Francisco Crime Classification\n",
    "\n",
    "From 2010 - 2015 the San Francisco police department made records crime reports from across all of San Francisco's neighborhoods. \n",
    "\n",
    "Your task is **to predict if the crime was theft or not!**\n",
    "\n",
    "![](https://digital.ihg.com/is/image/ihg/holiday-inn-san-francisco-6019097353-2x1)\n",
    "\n",
    "The following information has been recorded in our data: \n",
    "* `Dates` - timestamp of the crime incident\n",
    "* `Category` - category of the crime incident. \n",
    "* `Descript` - detailed description of the crime incident\n",
    "* `PdDistrict` - name of the Police Department District\n",
    "* `Resolution` - how the crime incident was resolved\n",
    "* `Address` - the approximate street address of the crime incident\n",
    "* `X` - Longitude\n",
    "* `Y` - Latitude\n",
    "* `Theft` - A flag that states if the crime was a theft or larcency. **This is the target variable you are going to predict.**\n",
    "\n",
    "Our target is **Theft**. This column was created from the `Category`column which contains more detailed categories of crime.\n",
    "\n",
    "This dataset and the corresponding challenge was part of a competition hosted by Kaggle and many people have attempted to solve this problem before you. Take a look at what people have tried at the [Kaggle site](https://www.kaggle.com/c/sf-crime/notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "Use this next cell to import the libraries you need, pandas is already done for you. If you need more the further down the notebook you get come back and add them to this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to follow\n",
    "\n",
    "We are going to follow the following project steps:\n",
    "\n",
    "- Import the data\n",
    "- Exploratory Data Analysis\n",
    "- In-depth Data Analysis\n",
    "- Feature Engineering\n",
    "- Preparing the Data for Sci-kit Learn\n",
    "- Use a transformer on categorical features\n",
    "- Build a pipeline\n",
    "- Using grid search on model parameters\n",
    "- Analysing model predictive power\n",
    "- Further improvements\n",
    "- Conclusion/suggestions for future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "\n",
    "First import the data from the `sf_crime_hackathon.csv` in the `/data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime = pd.read_csv('data/sf_crime_hackathon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "### Part 1: Exploratory Analysis\n",
    "Have a quick look at the data using these methods:\n",
    "\n",
    "- `df.head()`, `df.tail()`, `df.sample(5)`\n",
    "- `df.shape`\n",
    "- `df.describe()`\n",
    "- `df.info()`\n",
    "- `df.dtypes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to clean the data a bit before moving on.\n",
    "\n",
    "Re-read the data in and add parameters to `.read_csv()` and chain methods to:\n",
    "- parse the type of the `dates` column: make sure they are datetimes instead of strings;\n",
    "- rename the colums to be all lower case (or upper if you prefer);\n",
    "- rename the column `dates` to be `date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: In-depth Analysis (with optional visualisations)\n",
    "\n",
    "Answer the following questions. You can also visualise your results using `.plot()` if you want. \n",
    "\n",
    "1. Have a look at the different columns in the data. Which ones do you have access to now, but not once the model is actually being used? What should you do when training the model?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How many missing values are there in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How many unique values for address are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What are the top 10 largest categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Which month has the most amount of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which district has the most amount of crime? Which has the least?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What are the 10 most/least occuring crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Now you're going to create some new features for our model. Let's start by creating new features from our `date` feature. If you converted this column to a Timestamp, you can easily extract several [date properties](https://pandas.pydata.org/docs/reference/arrays.html#properties)!\n",
    "\n",
    "\n",
    "Create the following columns and drop the original `date` column:\n",
    "- `n_days`: Number of days since the first date in the dataset\n",
    "- `day`: The day of the year\n",
    "- `weekday`: The day of the week\n",
    "- `month`: The month of the year\n",
    "- `year`: The year\n",
    "- `hour`: The hour of the day\n",
    "- `minute`: The minute of the hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the features have been created correctly. What is the max and min of the new features? Is that what you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make some extra features. The address column will be an issue since there are over 22,000 unique values. You also probably want to drop such sensitive data. Instead let's create:\n",
    "- `is_block`: Take the value of True if the `address` feature has the word `Block` in\n",
    "- `x_minus_y`: The difference between `x` and `y`\n",
    "- `x_plus_y`: The sum of `x` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Add at least 2 extra features.\n",
    "\n",
    "Potential features:\n",
    "\n",
    "- Any special date fields\n",
    "- Features based on past observations (e.g. crime in the same area during the past year)\n",
    "- Converting categorical features (`pddistrict`) into numeric using target encoding\n",
    "- Any other combination of features\n",
    "- External features (from other datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for sci-kit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you will need to separate the features and target.\n",
    "\n",
    "Note that two features will need to be dropped:\n",
    "- `descript` - detailed description of the crime incident, therefore a more detailed version of the **target feature**\n",
    "- `resolution` - how the crime incident was resolved. This is created after the target was defined, and cannot be used to predict a new crime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create X and y. \n",
    "\n",
    "- X should have the following features (plus whatever bespoke ones you've created): \n",
    "```python\n",
    "'pddistrict', 'x', 'y','n_days', 'day', 'dayofweek', 'month', 'year', 'hour', 'minute', 'x_minus_y', 'x_plus_y', 'is_block'\n",
    "```\n",
    "- y should only have one feature: `theft`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at which features are categorical (`object` data types):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have some non-numeric data that you will need to change later! (`pddistrict`, `address`)\n",
    "\n",
    "First let's split into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a base-line model\n",
    "\n",
    "Choose a model to build and use the raw data to build a base-line model. Drop all missing rows.\n",
    "\n",
    "How does your model perform? How do other algorithms perform? Why are some better than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding\n",
    "\n",
    "You can use one-hot encoding to convert the categorical features, or just drop them for now while building a baseline model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ColumnTransformer\n",
    "\n",
    "Let's include `ColumnTransformer()` so that we can apply the onehotencoder to only the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a pipeline\n",
    "\n",
    "Now that we know we have to transform our data using a sklearn transformer, it would be good to package this up into a pipeline.\n",
    "\n",
    "Let's build a RandomForest to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch\n",
    "\n",
    "Now let's see if you can hypertune these parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "So far you've looked at Accuracy Score, F1-Score, Recall and Precision. Can you create an output that reports these metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "Now that you have your model, can you look at the feature importance to reduce the features in your model and still maintain the score?\n",
    "\n",
    "To access the feature importance you must:\n",
    "\n",
    "1. access the model from the pipeline: `pipeline['model']`\n",
    "2. access the feature importances attribute using `.feature_importances_`\n",
    "\n",
    "You can then plot this against the feature names (`.get_feature_names_`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild the model using fewer characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
