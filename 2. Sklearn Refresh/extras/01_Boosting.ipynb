{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attached-columbus",
   "metadata": {},
   "source": [
    "<img src='../images/gdd-logo.png' width='300px' align='right' style=\"padding: 15px\">\n",
    "\n",
    "\n",
    "# Boosting\n",
    "\n",
    "In this notebook, we shall discuss some of the most performant machine learning models for tabular data and provide you an opportunity to practise the skills we have been refreshing.\n",
    "\n",
    "**Program**\n",
    "- [Preparing the data](#explore)\n",
    "- [Overview of Ensemble Methods](#ensemble)\n",
    "- [Gradient Boosting](#boosting)\n",
    "- [Make a baseline model](#baseline)\n",
    "- [Sklearn transformers](#transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-hurricane",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Let's load in the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de45f6a-6b51-4029-b732-22c2f6b3a926",
   "metadata": {},
   "source": [
    "<a id=about></a>\n",
    "## About the data\n",
    "\n",
    "<img src='../images/who.png' width='500px' align='right' style=\"padding: 15px\">\n",
    "\n",
    "According to the World Health Organization (WHO), strokes are the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.\n",
    "\n",
    "You will use this dataset to build a model that can **predict whether a patient is likely to have a `stroke`** (based on input parameters like gender, age and whether or not they smoke). \n",
    "\n",
    "Each row in the data provides relavant information about the patient.\n",
    "### Features\n",
    "\n",
    "1. `id`: unique identifier\n",
    "1. `address`: a general address (city/county, state and postal code)\n",
    "1. `gender`: \"Male\", \"Female\" or \"Other\"\n",
    "1. `age`: age of the patient\n",
    "1. `hypertension`: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
    "1. `heart_disease`: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
    "1. `ever_married`: \"No\" or \"Yes\"\n",
    "1. `work_type`: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
    "1. `residence_type`: \"Rural\" or \"Urban\"\n",
    "1. `avg_glucose_level`: average glucose level in blood\n",
    "1. `bmi`: body mass index\n",
    "1. `smoking_status`: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"\n",
    "1. `stroke`: 1 if the patient had a stroke or 0 if not\n",
    "\n",
    "*Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959da651",
   "metadata": {},
   "source": [
    "Let's prepare the data for your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke = pd.read_csv('../data/stroke.csv').rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable definitions\n",
    "categorical_cols = ['work_type', 'smoking_status', 'who', 'gender', 'residence_type']\n",
    "missing_cols = ['age','bmi']\n",
    "drop_cols = ['id','address']\n",
    "\n",
    "target = 'stroke'\n",
    "\n",
    "def create_Xy(df, drop_cols, target_col):\n",
    "    df = df.drop(columns=drop_cols)\n",
    "    return (\n",
    "        df.drop(columns=target_col),\n",
    "        df[target_col]\n",
    "    )\n",
    "\n",
    "# Create X and y\n",
    "X, y = stroke.pipe(create_Xy, \n",
    "                   drop_cols=drop_cols, \n",
    "                   target_col=target,\n",
    "                   )\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 123,\n",
    "                                                    stratify = y,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-bleeding",
   "metadata": {},
   "source": [
    "<a id=ensemble></a>\n",
    "\n",
    "## Overview of Ensemble Methods\n",
    "\n",
    "Ensemble methods enhance model performance by combining multiple individual models, resulting in a more expressive and flexible overall model. This approach effectively reduces model bias and variance, making the model less specific to the training dataset.\n",
    "\n",
    "Two popular approaches to ensembling methods are **bagging** and **boosting**:\n",
    "\n",
    " - **Bagging**: aggregates the predictions of individual models that were trained in a *parallel* (on bootrapped subsamples of the data). \n",
    "\n",
    "- **Boosting**: individual models are trained *sequentially*, with each subsequent model learning from the mistakes of the one that came before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-virgin",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "Gradient boosting is a form of boosting.\n",
    "\n",
    "Individual trees are trained sequentially to address the mistakes, or **residual error**, of the models that came before.\n",
    "\n",
    "<img src=\"../images/gradient-boosting.png\" style=\"display: block;margin-left: auto;margin-right: auto;height: 400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bccc53",
   "metadata": {},
   "source": [
    "You're going to train a gradient boosting model. In order to do that, let's first create a preprocessing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de064c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(drop=\"if_binary\"), categorical_cols)\n",
    "], remainder='passthrough')\n",
    "\n",
    "preprocessing = Pipeline(steps=[\n",
    "    ('onehot', onehot),\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-wings",
   "metadata": {},
   "source": [
    "You can use the `GradientBoostingClassifier` from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model_boosting = GradientBoostingClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c01582",
   "metadata": {},
   "source": [
    "And combine the two into one `Pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_boosting = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('model', model_boosting)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc075717",
   "metadata": {},
   "source": [
    "Finally fit and score the model (just like you did in the previous notebooks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_boosting.fit(X_train, y_train)\n",
    "\n",
    "pipeline_boosting.score(X_train, y_train), pipeline_boosting.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "boosting_preds = pipeline_boosting.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, boosting_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "RocCurveDisplay.from_estimator(pipeline_boosting, X_train, y_train, ax=ax, name='Train')\n",
    "RocCurveDisplay.from_estimator(pipeline_boosting, X_test, y_test, ax=ax, name='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-workplace",
   "metadata": {},
   "source": [
    "## XGBoost & LightGBM \n",
    "\n",
    "For larger datasets, you may want to consider using [XGBoost](https://xgboost.readthedocs.io/) or [LightGBM](https://lightgbm.readthedocs.io)\\.\n",
    "\n",
    "They are gradient boosting methods that were designed for optimal computational speed and model performance.\n",
    "\n",
    "Below we demonstrate an example using XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgboost = XGBClassifier(objective=\"multi:softmax\", num_class=2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgboost = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('model', model_xgboost)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgboost.fit(X_train, y_train)\n",
    "\n",
    "pipeline_xgboost.score(X_train, y_train), pipeline_xgboost.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_preds = pipeline_xgboost.predict(X_test)\n",
    "print(classification_report(y_test, xgboost_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-respect",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "RocCurveDisplay.from_estimator(pipeline_xgboost, X_train, y_train, ax=ax, name='Train')\n",
    "RocCurveDisplay.from_estimator(pipeline_xgboost, X_test, y_test, ax=ax, name='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-republic",
   "metadata": {},
   "source": [
    "### <mark>Exercise</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-healing",
   "metadata": {},
   "source": [
    "Sckit Learn has a native implementation of [Histogram Boosting](https://scikit-learn.org/stable/modules/ensemble.html#histogram-based-gradient-boosting), which was inspired by LightGBM. Implement the model in your pipeline and investigate what level of performance you can achieve on the data.\n",
    "\n",
    "**Steps:**\n",
    "1. Define the model\n",
    "2. Incorporate it into your pipeline\n",
    "3. Tune the pipeline's parameters by cross-validating it on the training data\n",
    "4. Use different metrics to evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632bfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../answers/04-histo-boosting.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-knock",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../images/gdd-logo.png' width='300px' align='right' style=\"padding: 15px\">\n",
    "\n",
    "<a id=conc></a>\n",
    "\n",
    "# Conclusion and Next Steps\n",
    "\n",
    "This notebook has covered an overview of high-performant boosting algorithms and provided an opportunity to practise best-practice for training and evaluating ML models with Scikit-Learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
